{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection And Recognition using OpenCV in Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Project we have complete whole program in such devided parts:\n",
    "            1. Import all required modules \n",
    "            2. Create module to complete all necessoary tasks.(i.e Function)\n",
    "            3. Creating DataSets using web cam\n",
    "            4. Collecting Data (images)\n",
    "            5. Recognition\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To detect the face of person in web cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):   \n",
    "    detector = cv2.CascadeClassifier(\"frontal_face.xml\")\n",
    "    faces = detector.detectMultiScale(frame,1.2,5)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use to convert \"color\" images into \"black & white\" images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### use to cut main face and leave other part of person "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_faces(image, faces_coord):\n",
    "    faces = [] \n",
    "    for (x, y, w, h) in faces_coord:\n",
    "        faces.append(image[y: y + h, x : x + w ]) #y is row..y+h number of rows,x is column x+w number of columns     \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use to adjust brightness/intensity of image so that image will be more clean  \n",
    "image is be taken may be in low light or high light place this wwill adjust and make a clean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_intensity(images):\n",
    "    images_norm = []\n",
    "    for image in images:\n",
    "        images_norm.append(cv2.equalizeHist(image))\n",
    "    return images_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Image\n",
    " \n",
    " This module is use for zoom in Or zoom out the image so that cam feel comfort to take images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(images,size=(47,62)):\n",
    "    image_resize = []\n",
    "    for image in images:\n",
    "        if image.shape < size:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_CUBIC)\n",
    "        else:\n",
    "            img_size = cv2.resize(image,size,interpolation=cv2.INTER_AREA)\n",
    "        image_resize.append(img_size)    \n",
    "    return image_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Pipeline of all Image Editing Functions:\n",
    "\n",
    "\n",
    "To make image more clear and adjust intensity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_faces(frame, faces_coord):\n",
    "    faces = cut_faces(frame, faces_coord)\n",
    "    faces = normalize_intensity(faces)\n",
    "    faces = resize(faces)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Image \n",
    "\n",
    "This module is use to plot images in 2D (black & white) from 3D (colorfull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_show(image,title=\"\"):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image,cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Border of Frame for Face Detection:\n",
    "\n",
    "The border of rectanle marks on persons face in color with RGB combination (50,0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image, coords):\n",
    "    for (x, y, w, h) in coords:\n",
    "        cv2.rectangle(image, (x , y), (x + w , y + h), (50,0,255),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Datasets using web cam\n",
    "\n",
    "This cell participate in our whole project to open cam and take images and count them and as we have give limitation of 100 img It count img and when it reach 100 it will auto-stop to taking image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter No. of Persons: 3\n",
      "Person 1: adarshji\n",
      "This name already exists.\n",
      "Person 2: vinit1\n",
      "This name already exists.\n",
      "Person 3: anans\n",
      "This name already exists.\n"
     ]
    }
   ],
   "source": [
    "count = int(input('Enter No. of Persons: '))\n",
    "\n",
    "for i in range(1, count+1): #loop to count no of persons\n",
    "    cam = cv2.VideoCapture(0)#web cam on\n",
    "    folder = \"faces/\"+input('Person {}: '.format(i)).lower()\n",
    "    \n",
    "    if not os.path.exists(folder): #selecting path and folder\n",
    "        os.mkdir(folder)\n",
    "        flag_start_capturing = False\n",
    "        sample=1\n",
    "        cv2.namedWindow(\"Face\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "        while True:\n",
    "            ret,frame = cam.read()\n",
    "            gray = gray_scale(frame)\n",
    "            faces_coord = detect_face(gray)\n",
    "\n",
    "            if len(faces_coord):\n",
    "                faces = normalize_faces(gray,faces_coord)\n",
    "                cv2.imwrite(folder + '/' + str(sample)+'.jpg',faces[0])\n",
    "                plot_show(faces[0],\"Capture Count:\"+str(sample))\n",
    "                clear_output(wait=True)\n",
    "                if flag_start_capturing == True:\n",
    "                    sample += 1\n",
    "            \n",
    "            draw_rectangle(frame,faces_coord)\n",
    "            cv2.imshow('Face',frame)\n",
    "            keypress=cv2.waitKey(1)\n",
    "        \n",
    "            if keypress == ord('c'):\n",
    "                if flag_start_capturing == False:\n",
    "                    flag_start_capturing = True\n",
    "        \n",
    "            if sample >100: # Capture Count of images\n",
    "                break\n",
    "            \n",
    "            if keypress == ord('q'): # Quit ->>>> to close the cam press q\n",
    "                break\n",
    "\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print (\"This name already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Collecting  Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using this cell we collect our all images in our created folder i.e. \"faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_dataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "    labels_dic = {}\n",
    "   \n",
    "    people = [Anans for Anans in os.listdir(\"faces/\")]\n",
    "   \n",
    "    for i, Anans in enumerate(people):\n",
    "        labels_dic[i] = Anans\n",
    "        for image in os.listdir(\"faces/\" + Anans):\n",
    "            if image.endswith('.jpg'):\n",
    "                images.append(cv2.imread(\"faces/\" + Anans + '/' + image, 0))\n",
    "                labels.append(i)\n",
    "    return (images, np.array(labels), labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, labels_dic = collect_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "{0: '.ipynb_checkpoints', 1: 'adarshji', 2: 'anans', 3: 'vinit1'}\n"
     ]
    }
   ],
   "source": [
    "print (len(images))\n",
    "print (labels_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 47)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300, 62, 47)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train))\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.reshape(len(train),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2914)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train_sc = sc.fit_transform(x_train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=.97)\n",
    "x_train_pca = pca.fit_transform(x_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l2', 'l1'], 'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = {'C':[.001,.01,.1,1,10],'penalty':['l2','l1']}\n",
    "gd_log = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid = param, cv=5, scoring='accuracy')\n",
    "gd_log.fit(x_train_pca,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gd_log.best_score_)\n",
    "gd_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_log = gd_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Face_Detection_log.pkl'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(clf_log, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Face_Detection_log.pkl'\n",
    "clf_log_load = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### recognise face of saved person like in this I use 3 persons named 1. Anans 2. Vinit1 3. Adarshji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44341354  4.10380667 -4.82970196]]\n",
      "[[0.28274593 0.71152174 0.00573233]]\n",
      "[2] 2\n",
      "Anans\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "cv2.namedWindow(\"opencv_face\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cam.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces_coord = detect_face(gray) # detect more than one face\n",
    "    if len(faces_coord):\n",
    "        faces = normalize_faces(gray, faces_coord)\n",
    "        faces = normalize_intensity(faces)\n",
    "        for i, face in enumerate(faces): # for each detected face\n",
    "            x_test = face.reshape(1,-1)\n",
    "            x_test_sc = sc.transform(x_test.astype(np.float64))\n",
    "            x_test_pca = pca.transform(x_test_sc)    \n",
    "            \n",
    "            prob = gd_log.predict_proba(x_test_pca)\n",
    "            confidence = gd_log.decision_function(x_test_pca)\n",
    "            print (confidence)\n",
    "            print (prob)\n",
    "           \n",
    "            y_pred = gd_log.predict(x_test_pca)\n",
    "            print (y_pred, y_pred[0])\n",
    "           \n",
    "            name = labels_dic[y_pred[0]].capitalize()\n",
    "            print(name)\n",
    "            \n",
    "            if prob[0][0]>.9:\n",
    "                cv2.putText(frame, 'vivek', (faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 2, (66, 53, 243), 2)\n",
    "                \n",
    "            elif prob[0][1]>.85:\n",
    "                cv2.putText(frame, 'anand', (faces_coord[i][0], faces_coord[i][1] - 10),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 3, (66, 53, 243), 2)\n",
    "                  \n",
    "        clear_output(wait = True)\n",
    "        draw_rectangle(frame, faces_coord) # rectangle around face\n",
    "        \n",
    "    cv2.putText(frame, \"ESC to exit\", (5, frame.shape[0] - 5),cv2.FONT_HERSHEY_PLAIN, 1.3, (66, 53, 243), 2,cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"opencv_face\", frame) # live feed in external\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#            Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
